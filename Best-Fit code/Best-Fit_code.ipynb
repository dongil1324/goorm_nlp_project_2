{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22236,"status":"ok","timestamp":1659330897853,"user":{"displayName":"조동일","userId":"13043427476096709949"},"user_tz":-540},"id":"05F4z0LSYVJc","outputId":"ea4fdfa1-0e9a-418e-8e1b-1071c68ac294"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os, sys\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1659330901382,"user":{"displayName":"조동일","userId":"13043427476096709949"},"user_tz":-540},"id":"HEpS_HbIag0h"},"outputs":[],"source":["my_path = '/content/notebooks'\n","os.symlink('/content/drive/MyDrive/Colab Notebooks/my_env', my_path)\n","sys.path.insert(0, my_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xvdz4fk-j3PQ"},"outputs":[],"source":["! pip install wandb\n","! pip install datasets\n","! pip install transformers\n"]},{"cell_type":"code","source":["!pip install nvidia-smi\n","!nvidia-smi"],"metadata":{"id":"VNd06yf2ns6Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":883,"status":"ok","timestamp":1659330938881,"user":{"displayName":"조동일","userId":"13043427476096709949"},"user_tz":-540},"id":"IC-2efixa9cP","outputId":"1d3a1126-b02f-4642-851d-0044c2bcce5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/goorm/goorm-project-2-korean_mrc/Best-Fit code\n"]}],"source":["%cd /content/drive/MyDrive/goorm/goorm-project-2-korean_mrc/Best-Fit code"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1658975520039,"user":{"displayName":"조동일","userId":"13043427476096709949"},"user_tz":-540},"id":"VRwc9IIwb01J","outputId":"cbdb1eff-828c-474d-8701-e1022c4a83ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best-Fit_code.ipynb  inference_KoB.py  out\t\t train_KoB.py\n","data\t\t     max_answer_40     __pycache__\t wandb\n","dataset.py\t     modules\t       requirements.txt\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29252,"status":"ok","timestamp":1659347358245,"user":{"displayName":"조동일","userId":"13043427476096709949"},"user_tz":-540},"id":"aMnWGrjEcRSZ","outputId":"03dbe9fd-915f-4e5f-a4a5-ad439c01e1a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape (10434, 5)\n","train length: 8347, validation length: 2087\n","finished preprocessing\n"]}],"source":["!python ./modules/preprocess_KoB.py --data_path './data' --save_path './data' --pretrained_model_name 'monologg/kobigbird-bert-base' --max_length 1024 --train_fn 'pre_train.json'"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"AS8weWJrNe_N","executionInfo":{"status":"ok","timestamp":1659347377075,"user_tz":-540,"elapsed":8038,"user":{"displayName":"조동일","userId":"13043427476096709949"}}},"outputs":[],"source":["import torch\n","\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAl4kO26jMPN"},"outputs":[],"source":["!python ./train_KoB.py --model_fn 'pre_train_Data' --file_path './data' --pretrained_model_name 'monologg/kobigbird-bert-base' --n_epochs 2 --batch_size_per_device 4 --n_best 5 --max_answer_length 15"]},{"cell_type":"code","source":["!ls -a"],"metadata":{"id":"mWq2g9RblM3g","executionInfo":{"status":"ok","timestamp":1659078981551,"user_tz":-540,"elapsed":445,"user":{"displayName":"조동일","userId":"13043427476096709949"}},"outputId":"fdaf808d-abb1-47f1-afcb-128ab3d407e4","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline_Train_Data  inference_KoB.py\t\t __pycache__\n","Best-Fit_code.ipynb  max_answer_15_pre_news_2ep  requirements.txt\n",".cache\t\t     max_answer_40\t\t train_KoB.py\n",".checkpoints\t     max_answer_40_news\t\t wandb\n","data\t\t     modules\n","dataset.py\t     out\n"]}]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":123376,"status":"ok","timestamp":1659353004941,"user":{"displayName":"조동일","userId":"13043427476096709949"},"user_tz":-540},"id":"YquzMuYQnEWH","outputId":"716ad7c4-5910-4045-943f-232b45ae7462"},"outputs":[{"output_type":"stream","name":"stdout","text":["Some weights of the model checkpoint at monologg/kobigbird-bert-base were not used when initializing BigBirdForQuestionAnswering: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'bert.pooler.bias']\n","- This IS expected if you are initializing BigBirdForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BigBirdForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BigBirdForQuestionAnswering were not initialized from the model checkpoint at monologg/kobigbird-bert-base and are newly initialized: ['qa_classifier.qa_outputs.weight', 'qa_classifier.output.LayerNorm.bias', 'qa_classifier.intermediate.dense.weight', 'qa_classifier.qa_outputs.bias', 'qa_classifier.intermediate.dense.bias', 'qa_classifier.output.LayerNorm.weight', 'qa_classifier.output.dense.weight', 'qa_classifier.output.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","  0% 0/132 [00:00<?, ?it/s]./inference_KoB.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  x = torch.tensor(batch['input_ids']).to(device)\n","./inference_KoB.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  token_type_ids = torch.tensor(batch['token_type_ids']).to(device)\n","./inference_KoB.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_mask = torch.tensor(batch['attention_mask']).to(device)\n","/usr/local/lib/python3.7/dist-packages/transformers/models/big_bird/modeling_big_bird.py:983: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  * num_indices_to_pick_from\n","100% 132/132 [01:47<00:00,  1.23it/s]\n"]}],"source":["!python ./inference_KoB.py --model_fn 'pre_train_Data' --file_path './data' --pretrained_model_name 'monologg/kobigbird-bert-base' --n_best 5 --max_answer_length 15 --output_name 'pre_train_dev.csv'"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"2CZbGACHskMi","executionInfo":{"status":"ok","timestamp":1659352708458,"user_tz":-540,"elapsed":553,"user":{"displayName":"조동일","userId":"13043427476096709949"}}},"outputs":[],"source":["def levenshtein(s1, s2):\n","    # s2가 s1보다 길면 반대로 돌려서 계산\n","    if len(s1) < len(s2):\n","        return levenshtein(s2, s1)\n","    \n","    # s2의 길이가 0 이면 모두 추가 \n","    if len(s2) == 0:\n","        return len(s1)\n","\n","    # base 행 : [0,1,2...s2]\n","    previous_row = range(len(s2) + 1)\n","    for i, c1 in enumerate(s1): # s1에서 글자 하나씩 빼옴\n","        current_row = [i + 1] # 0~i 길이만큼 deletion이 일어났을 때의 비용\n","        for j, c2 in enumerate(s2): # s2에서 글자 하나씩 빼옴\n","            # 비용 계산\n","            insertions = previous_row[j + 1] + 1 \n","            deletions = current_row[j] + 1\n","            substitutions = previous_row[j] + (c1 != c2)\n","            current_row.append(min(insertions, deletions, substitutions))\n","\n","        previous_row = current_row\n","\n","    # s1 과 s2 끝부분끼리 비교부분 리턴\n","    return previous_row[-1]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lFfSRpHryC7g"},"outputs":[],"source":["def dev2csv(dataset, long_short):\n","    with open(\"dev.csv\", 'w') as fd:\n","        writer = csv.writer(fd)\n","        writer.writerow(['Id', 'Predicted'])\n","\n","        rows = [[sample['guid'], sample['answers'][long_short]['text']] for sample in dataset ]\n","        \n","        writer.writerows(rows)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"3hkTSU8ByCG6","executionInfo":{"status":"ok","timestamp":1659352713034,"user_tz":-540,"elapsed":550,"user":{"displayName":"조동일","userId":"13043427476096709949"}}},"outputs":[],"source":["def return2distance(data1 = \"dev.csv\", data2 = \"baseline.csv\"):\n","    try:\n","        df1 = pd.read_csv(data1, encoding = 'utf-8')\n","        df2 = pd.read_csv(data2, encoding = 'utf-8')\n","    except FileNotFoundError as e: \n","        print(e)\n","\n","    diff = []\n","\n","    for s1, s2 in zip(df1['Predicted'], df2['Predicted']):\n","        if type(s2) == float:\n","            s2 = str(s2)\n","        if type(s1) == float:\n","            s1 = str(s1)\n","    \n","        diff.append(levenshtein(s1, s2))\n","\n","    return sum(diff) / len(diff)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"VfPPVz_mzYFF","executionInfo":{"status":"ok","timestamp":1659352715912,"user_tz":-540,"elapsed":2368,"user":{"displayName":"조동일","userId":"13043427476096709949"}}},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":368,"status":"ok","timestamp":1659353017365,"user":{"displayName":"조동일","userId":"13043427476096709949"},"user_tz":-540},"id":"vU7nGpaByUFo","outputId":"8646bbc4-1942-44c8-feb8-c6f96a16682e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.068998562529947"]},"metadata":{},"execution_count":20}],"source":["return2distance(data1='./out/dev.csv', data2='./out/pre_train_dev.csv') #submission_best_fit.csv, result_votting.csv"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"t2gFn0-MzWV3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659353073446,"user_tz":-540,"elapsed":916,"user":{"displayName":"조동일","userId":"13043427476096709949"}},"outputId":"2ef25e34-c393-4c19-ae40-d16211b0c2d3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.435878243512974"]},"metadata":{},"execution_count":22}],"source":["return2distance(data1='./out/pre_train_.csv', data2='./out/submission_best_fit.csv') #submission_best_fit.csv, result_votting.csv"]},{"cell_type":"code","source":[""],"metadata":{"id":"CpRhf4uEJkug"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Best-Fit_code.ipynb","provenance":[],"background_execution":"on","authorship_tag":"ABX9TyM/+cPNufRSCKHCBIRX7iTC"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}